{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mdistilbert",
      "provenance": [],
      "collapsed_sections": [
        "sJsBpETWrSlk"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51427454acc7470aa7ce3f666b33ea0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f333a7666b9b404389e74c37cdd5dfa0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1de4638e3f13426ba08db8c5f74cd2f4",
              "IPY_MODEL_8a9db304d52342e3b9292029c319b7fe"
            ]
          }
        },
        "f333a7666b9b404389e74c37cdd5dfa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1de4638e3f13426ba08db8c5f74cd2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0d0a7cb03d74977b0eec0af1df57900",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c7a6660a0ab4e27aae6d85b86432f6f"
          }
        },
        "8a9db304d52342e3b9292029c319b7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7be603e7a8464bd198181653d2133fec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:03&lt;00:00, 334kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53828a2eddaa4d128fe5bb5b2df54af0"
          }
        },
        "e0d0a7cb03d74977b0eec0af1df57900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c7a6660a0ab4e27aae6d85b86432f6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7be603e7a8464bd198181653d2133fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53828a2eddaa4d128fe5bb5b2df54af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b873da9d0ee4fdbb3ddaf234d7c5ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf4ba00163d94908b47371e3225d3d6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1c255db847b4d1482f874db1e59eda2",
              "IPY_MODEL_cad8a50d733c438a80c7e86e92e81905"
            ]
          }
        },
        "bf4ba00163d94908b47371e3225d3d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1c255db847b4d1482f874db1e59eda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5daaf41e35b447599fa16db6fd3327c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_309c6b0c74bf46fc94335fed64f55e10"
          }
        },
        "cad8a50d733c438a80c7e86e92e81905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb06a1a6f4c0499e9512b1e446cbd722",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 485kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_878ce382b2614064a1f63f760c1fad83"
          }
        },
        "e5daaf41e35b447599fa16db6fd3327c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "309c6b0c74bf46fc94335fed64f55e10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb06a1a6f4c0499e9512b1e446cbd722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "878ce382b2614064a1f63f760c1fad83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2810be2f2da743c38231f374b68ba27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_277629a94b884cd3b2950ea922775185",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d74b478bcfdc4611a6ea1d2788a49fc4",
              "IPY_MODEL_af20f606c306421282d6d2eb295a5a1b"
            ]
          }
        },
        "277629a94b884cd3b2950ea922775185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d74b478bcfdc4611a6ea1d2788a49fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3521003705e24ecfb03b5d71640f2505",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42655cdf2c1a47b1bd0a63161cd30f13"
          }
        },
        "af20f606c306421282d6d2eb295a5a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68e886aeb98647d88a9cf8b0c39a2557",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 718/718 [00:01&lt;00:00, 360B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bde68c5d9f3b4da08b42604e8bcbdcf0"
          }
        },
        "3521003705e24ecfb03b5d71640f2505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42655cdf2c1a47b1bd0a63161cd30f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68e886aeb98647d88a9cf8b0c39a2557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bde68c5d9f3b4da08b42604e8bcbdcf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b691bc187a742b787bb76c71436112f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b10fa1776753456b8fbd595d1b6c8d58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_62e19e68e79d4852b5dd78361d18d917",
              "IPY_MODEL_ff87160dd7304b949f03c616e2d21986"
            ]
          }
        },
        "b10fa1776753456b8fbd595d1b6c8d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62e19e68e79d4852b5dd78361d18d917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4958ce41a61749caab8972be44e9804f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1520013706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1520013706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06698a1f119949fab15d6859e83d4416"
          }
        },
        "ff87160dd7304b949f03c616e2d21986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9be080bbc6742baaa5fe34d8625343d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.52G/1.52G [02:15&lt;00:00, 11.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_390f907280a34bef95b250ef02105c78"
          }
        },
        "4958ce41a61749caab8972be44e9804f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06698a1f119949fab15d6859e83d4416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9be080bbc6742baaa5fe34d8625343d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "390f907280a34bef95b250ef02105c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31d914bf649a43f1b13895e17248241d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ef0a7c9f23249cfb46d4c8df30dda76",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6cd388e9935f4c9c93177321c86b32df",
              "IPY_MODEL_204d7edc1afd4097a2adb1473132d909"
            ]
          }
        },
        "6ef0a7c9f23249cfb46d4c8df30dda76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6cd388e9935f4c9c93177321c86b32df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e693155fca64113ab74e2b38f1fa2de",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d2ee089914f4377b20c78753b443d46"
          }
        },
        "204d7edc1afd4097a2adb1473132d909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c90d07dda63480c813f5d021d79c145",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466/466 [02:02&lt;00:00, 3.81B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_897631369a124d3997a617ed5278100e"
          }
        },
        "2e693155fca64113ab74e2b38f1fa2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d2ee089914f4377b20c78753b443d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c90d07dda63480c813f5d021d79c145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "897631369a124d3997a617ed5278100e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "462b29fa9baa4be79130ca6e1580c40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1632e2cecb2941208bf208ff05289e32",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_70482f6c708642fab5d0293e14bf41f5",
              "IPY_MODEL_9626161cbf424101a9bee8c40bdb9085"
            ]
          }
        },
        "1632e2cecb2941208bf208ff05289e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70482f6c708642fab5d0293e14bf41f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c44d33dd2214b4f995718203507fb70",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 541808922,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 541808922,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8117d4105ac342f6bd17aa5c40de43d6"
          }
        },
        "9626161cbf424101a9bee8c40bdb9085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b783debe4c842ecbe7870249cc3eb16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 542M/542M [00:11&lt;00:00, 48.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86a02ac94b274befad9da7e1fb5617d8"
          }
        },
        "2c44d33dd2214b4f995718203507fb70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8117d4105ac342f6bd17aa5c40de43d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b783debe4c842ecbe7870249cc3eb16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86a02ac94b274befad9da7e1fb5617d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDR80nrpYJSZ",
        "outputId": "900fb8df-8c59-44bc-f662-18f1636737f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJsBpETWrSlk"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5DJt9KGoSf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a463f7-424b-4f3f-9ae6-bef96e13e80d"
      },
      "source": [
        "!git clone https://github.com/neuspell/neuspell\n",
        "%cd neuspell"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'neuspell'...\n",
            "remote: Enumerating objects: 653, done.\u001b[K\n",
            "remote: Counting objects: 100% (456/456), done.\u001b[K\n",
            "remote: Compressing objects: 100% (287/287), done.\u001b[K\n",
            "remote: Total 653 (delta 280), reused 303 (delta 151), pack-reused 197\u001b[K\n",
            "Receiving objects: 100% (653/653), 74.43 MiB | 21.51 MiB/s, done.\n",
            "Resolving deltas: 100% (306/306), done.\n",
            "/content/neuspell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiymHeLeoZfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92d34e1-1159-4a5b-b497-a3feab2d4f3b"
      },
      "source": [
        "!pip install -e ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/neuspell\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0) (1.19.5)\n",
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/58/06f430ff7607a2929f80f07bfd820acbc508a4e977542fefcc522cde9dff/jsonlines-2.0.0-py3-none-any.whl\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 50.5MB/s \n",
            "\u001b[?25hCollecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 60.4MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 60.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->neuspell==1.0.0) (3.7.4.3)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/8f/42959300c543b4d34bc9f9b54954471a33384c181084ed84f070763d7f37/boto3-1.17.62-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 69.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->neuspell==1.0.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->neuspell==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->neuspell==1.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->neuspell==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->neuspell==1.0.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->neuspell==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->neuspell==1.0.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->neuspell==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->neuspell==1.0.0) (3.4.1)\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.3MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.62\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/60/ba830f93176fdc23166043298173ee2aecd5cf150f1ede51d6506f021deb/botocore-1.20.62-py2.py3-none-any.whl (7.5MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5MB 62.8MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.62->boto3->pytorch_pretrained_bert->neuspell==1.0.0) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.62 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, jsonlines, sentencepiece, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, neuspell\n",
            "  Running setup.py develop for neuspell\n",
            "Successfully installed boto3-1.17.62 botocore-1.20.62 jmespath-0.10.0 jsonlines-2.0.0 neuspell pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LolSwfmocil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e317000a-3197-4739-e660-bbf9e38bdf4f"
      },
      "source": [
        "!pip install urllib3==1.25.4"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting urllib3==1.25.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/7777358f672a14b7ae0dfcd29f949f409f913e0578190d6bfa68eb55864b/urllib3-1.25.4-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 5.3MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed urllib3-1.25.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0owUYWg2pKTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986d3bae-3c5d-416d-ac05-75049bab92c4"
      },
      "source": [
        "!pip install folium==0.2.1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting folium==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/dd/75ced7437bfa7cb9a88b96ee0177953062803c3b4cde411a97d98c35adaf/folium-0.2.1.tar.gz (69kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (1.1.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-cp37-none-any.whl size=79979 sha256=72d0f8306faa7447c1a002de5146aed17d376482db21c243f419b207a7f846c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/09/f0/52d2ef419c2aaf4fb149f92a33e0008bdce7ae816f0dd8f0c5\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBqDR09Konge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd3061e-ab51-454d-b841-203a742956db"
      },
      "source": [
        "!pip install -r extras-requirements.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/neuspell (from -r extras-requirements.txt (line 1))\n",
            "Obtaining file:///content/neuspell (from -r extras-requirements.txt (line 2))\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0->-r extras-requirements.txt (line 1)) (4.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0->-r extras-requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0->-r extras-requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0->-r extras-requirements.txt (line 1)) (0.1.95)\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0->-r extras-requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from neuspell==1.0.0->-r extras-requirements.txt (line 1)) (2.2.4)\n",
            "Collecting allennlp==1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/56/1d3c00a8cec0d5d672c7a29980e0a468ea6287dc6e7ffd235cc6012c784d/allennlp-1.5.0-py3-none-any.whl (517kB)\n",
            "\u001b[K     |████████████████████████████████| 522kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.17.62)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (56.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.0.5)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 31.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (3.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (2.10.0)\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/1a/f2db026d4d682303793559f1c2bb425ba3ec0d6fd7ac63397790443f2461/jsonpickle-2.0.0-py2.py3-none-any.whl\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (3.6.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.25.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.62 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (1.20.62)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (3.12.4)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (1.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (20.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.5.0->neuspell==1.0.0->-r extras-requirements.txt (line 2)) (8.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.62->boto3->pytorch_pretrained_bert->neuspell==1.0.0->-r extras-requirements.txt (line 1)) (2.8.1)\n",
            "Building wheels for collected packages: jsonnet, overrides\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp37-cp37m-linux_x86_64.whl size=3388778 sha256=8066c1851179c8d0b9ca6a04201c75c89099ce71a7bcedcc437f3276fccee9bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=80281cb0b5b70b3237635d177a052e3212fd6d76aa1b248794ea5297a214a363\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "Successfully built jsonnet overrides\n",
            "\u001b[31mERROR: allennlp 1.5.0 has requirement torch<1.8.0,>=1.6.0, but you'll have torch 1.8.1+cu101 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: allennlp 1.5.0 has requirement transformers<4.3,>=4.1, but you'll have transformers 4.5.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jsonnet, jsonpickle, overrides, tensorboardX, allennlp, neuspell\n",
            "  Found existing installation: neuspell 1.0.0\n",
            "    Can't uninstall 'neuspell'. No files were found to uninstall.\n",
            "  Running setup.py develop for neuspell\n",
            "Successfully installed allennlp-1.5.0 jsonnet-0.17.0 jsonpickle-2.0.0 neuspell overrides-3.1.0 tensorboardX-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFTbuKdqos-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96abfd1-4464-400f-c7b4-64eb06a19e73"
      },
      "source": [
        "!pip install torch==1.6.0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: allennlp 1.5.0 has requirement transformers<4.3,>=4.1, but you'll have transformers 4.5.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed torch-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se7YcT-Tphfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d84cdc23-1560-4158-a6dc-109df1dd8458"
      },
      "source": [
        "!pip install transformers==4.1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/40/b1b8b0cad8eb37a7f9362a6c3930445bdf9dd745cdf6cbfce682fed4aef0/transformers-4.1.0-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.1) (1.19.5)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/36/59e4a62254c5fcb43894c6b0e9403ec6f4238cc2422a003ed2e6279a1784/tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.1) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.1) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.1) (0.0.45)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1) (1.25.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.1) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1) (7.1.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Found existing installation: tokenizers 0.10.2\n",
            "    Uninstalling tokenizers-0.10.2:\n",
            "      Successfully uninstalled tokenizers-0.10.2\n",
            "  Found existing installation: transformers 4.5.1\n",
            "    Uninstalling transformers-4.5.1:\n",
            "      Successfully uninstalled transformers-4.5.1\n",
            "Successfully installed tokenizers-0.9.4 transformers-4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaaDd1X7DZll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "51427454acc7470aa7ce3f666b33ea0b",
            "f333a7666b9b404389e74c37cdd5dfa0",
            "1de4638e3f13426ba08db8c5f74cd2f4",
            "8a9db304d52342e3b9292029c319b7fe",
            "e0d0a7cb03d74977b0eec0af1df57900",
            "3c7a6660a0ab4e27aae6d85b86432f6f",
            "7be603e7a8464bd198181653d2133fec",
            "53828a2eddaa4d128fe5bb5b2df54af0",
            "9b873da9d0ee4fdbb3ddaf234d7c5ece",
            "bf4ba00163d94908b47371e3225d3d6d",
            "a1c255db847b4d1482f874db1e59eda2",
            "cad8a50d733c438a80c7e86e92e81905",
            "e5daaf41e35b447599fa16db6fd3327c",
            "309c6b0c74bf46fc94335fed64f55e10",
            "bb06a1a6f4c0499e9512b1e446cbd722",
            "878ce382b2614064a1f63f760c1fad83",
            "2810be2f2da743c38231f374b68ba27d",
            "277629a94b884cd3b2950ea922775185",
            "d74b478bcfdc4611a6ea1d2788a49fc4",
            "af20f606c306421282d6d2eb295a5a1b",
            "3521003705e24ecfb03b5d71640f2505",
            "42655cdf2c1a47b1bd0a63161cd30f13",
            "68e886aeb98647d88a9cf8b0c39a2557",
            "bde68c5d9f3b4da08b42604e8bcbdcf0",
            "0b691bc187a742b787bb76c71436112f",
            "b10fa1776753456b8fbd595d1b6c8d58",
            "62e19e68e79d4852b5dd78361d18d917",
            "ff87160dd7304b949f03c616e2d21986",
            "4958ce41a61749caab8972be44e9804f",
            "06698a1f119949fab15d6859e83d4416",
            "b9be080bbc6742baaa5fe34d8625343d",
            "390f907280a34bef95b250ef02105c78"
          ]
        },
        "outputId": "7bff59bc-b57d-48ee-d3dd-3d7b0d2a345a"
      },
      "source": [
        "import neuspell"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data folder is set to `/content/neuspell/neuspell/../data` script\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51427454acc7470aa7ce3f666b33ea0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b873da9d0ee4fdbb3ddaf234d7c5ece",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2810be2f2da743c38231f374b68ba27d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=718.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b691bc187a742b787bb76c71436112f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1520013706.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r16B7f6EqCzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c17173-6fb4-4382-f6dd-4322cef62452"
      },
      "source": [
        "%cd data/traintest\n",
        "!python download_datafiles.py "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/neuspell/data/traintest\n",
            "./wo_context created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAH8SYjqWqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cecba3a-40b0-49e0-bde7-b55d373dd63e"
      },
      "source": [
        "%cd /content/neuspell"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/neuspell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIX83hQaU_4S"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZMoUfq1xOso"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from neuspell.seq_modeling.subwordbert import load_model\n",
        "from neuspell.seq_modeling.helpers import load_data, train_validation_split, batch_accuracy_func\n",
        "from neuspell.seq_modeling.helpers import get_tokens, progressBar\n",
        "from neuspell.seq_modeling.helpers import batch_iter, labelize, tokenize, bert_tokenize_for_valid_examples\n",
        "\n",
        "from neuspell.seq_modeling.helpers import load_vocab_dict, save_vocab_dict"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsq2r8BYxQRd"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TKBAuP2_7KL"
      },
      "source": [
        "## Load dataset, vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1vujZqTxWBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47df54a7-f478-4e72-8553-77a6a33c2e93"
      },
      "source": [
        "train_data = load_data('/content/neuspell/data/traintest/','test.1blm','test.1blm.noise.prob')\n",
        "\n",
        "train_data, valid_data = train_validation_split(train_data, 0.90, seed=1)\n",
        "\n",
        "vocab_ref = {}\n",
        "\n",
        "vocab = get_tokens([i[0] for i in train_data],\n",
        "                           keep_simple=True,\n",
        "                           min_max_freq=(2,float(\"inf\")),\n",
        "                           topk=100000,\n",
        "                           intersect=vocab_ref,\n",
        "                           load_char_tokens=True)\n",
        "\n",
        "# save_vocab_dict('/content/drive/MyDrive/NLP/bert_vocab.pkl', vocab)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "273134it [00:00, 367737.35it/s]\n",
            "273134it [00:00, 1348640.87it/s]\n",
            "  0%|          | 0/245821 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loaded tuples of (corr,incorr) examples from /content/neuspell/data/traintest/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245821/245821 [00:01<00:00, 158972.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total tokens found: 155272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/245821 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total tokens retained: 139243\n",
            "Total tokens retained: 67965\n",
            "Total tokens retained: 67965\n",
            "loading character tokens\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245821/245821 [00:01<00:00, 197668.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of unique chars found: 98\n",
            "{'<<CHAR_UNK>>': 0, '<<CHAR_PAD>>': 1, '<<CHAR_START>>': 2, '<<CHAR_END>>': 3, 'H': 4, 'e': 5, ' ': 6, 'w': 7, 'a': 8, 's': 9, 'b': 10, 'r': 11, 'i': 12, 'f': 13, 'l': 14, 'y': 15, 'h': 16, 'o': 17, 'p': 18, 't': 19, 'z': 20, 'd': 21, 'n': 22, 'c': 23, 'k': 24, 'j': 25, 'u': 26, '.': 27, 'A': 28, 'm': 29, 'B': 30, 'g': 31, 'G': 32, 'M': 33, '3': 34, 'v': 35, ',': 36, '7': 37, '6': 38, '2': 39, 'T': 40, 'D': 41, 'S': 42, 'E': 43, '1': 44, '-': 45, 'x': 46, '4': 47, '9': 48, '(': 49, 'U': 50, 'P': 51, 'I': 52, ')': 53, \"'\": 54, ';': 55, 'q': 56, '\"': 57, '?': 58, 'Y': 59, 'C': 60, 'O': 61, 'K': 62, 'L': 63, 'N': 64, 'R': 65, 'W': 66, '0': 67, '8': 68, 'J': 69, ':': 70, 'F': 71, '5': 72, '%': 73, 'V': 74, '/': 75, '$': 76, 'Z': 77, 'Q': 78, '!': 79, '[': 80, ']': 81, 'X': 82, '&': 83, '@': 84, '+': 85, '_': 86, '#': 87, '*': 88, '|': 89, '>': 90, '^': 91, '\\\\': 92, '=': 93, '<': 94, '~': 95, '{': 96, '}': 97}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Y6NsXyADRe"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOxXin23x1Q1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "31d914bf649a43f1b13895e17248241d",
            "6ef0a7c9f23249cfb46d4c8df30dda76",
            "6cd388e9935f4c9c93177321c86b32df",
            "204d7edc1afd4097a2adb1473132d909",
            "2e693155fca64113ab74e2b38f1fa2de",
            "4d2ee089914f4377b20c78753b443d46",
            "1c90d07dda63480c813f5d021d79c145",
            "897631369a124d3997a617ed5278100e",
            "462b29fa9baa4be79130ca6e1580c40e",
            "1632e2cecb2941208bf208ff05289e32",
            "70482f6c708642fab5d0293e14bf41f5",
            "9626161cbf424101a9bee8c40bdb9085",
            "2c44d33dd2214b4f995718203507fb70",
            "8117d4105ac342f6bd17aa5c40de43d6",
            "2b783debe4c842ecbe7870249cc3eb16",
            "86a02ac94b274befad9da7e1fb5617d8"
          ]
        },
        "outputId": "d55d928a-5c45-4ff8-f407-5099e41b0817"
      },
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "bert_pretrained_name_or_path = \"distilbert-base-multilingual-cased\"\n",
        "model = load_model(vocab,\"distilbert-base-multilingual-cased\")\n",
        "model = model.cuda()\n",
        "\n",
        "\n",
        "VALID_BATCH_SIZE = 32\n",
        "\n",
        "data_iter = batch_iter(train_data, batch_size=VALID_BATCH_SIZE, shuffle=False)\n",
        "\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "\n",
        "DEVICE = 'cuda'\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31d914bf649a43f1b13895e17248241d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "462b29fa9baa4be79130ca6e1580c40e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=541808922.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of parameters in the model: 187001472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiOvZITX_wpf"
      },
      "source": [
        "## freeze layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKOHTfURHwZH"
      },
      "source": [
        "# for layers in model.bert_model.encoder.layer[:9]:\n",
        "#     for param in layers.parameters():\n",
        "#         param.requires_grad = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-NZQEzCAFiq"
      },
      "source": [
        "## Bert optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCxdnfu1AJQw"
      },
      "source": [
        "START_EPOCH = 1\n",
        "N_EPOCHS = 5\n",
        "\n",
        "GRADIENT_ACC = 4\n",
        "max_dev_acc, argmax_dev_acc = -1, -1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_2wJjsRKvZH"
      },
      "source": [
        "# from pytorch_pretrained_bert import BertAdam\n",
        "\n",
        "# param_optimizer = list(model.named_parameters())\n",
        "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "# optimizer_grouped_parameters = [\n",
        "#     {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "#     {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "# ]\n",
        "# t_total = int(len(train_data) / TRAIN_BATCH_SIZE / GRADIENT_ACC * N_EPOCHS)\n",
        "# optimizer = BertAdam(optimizer_grouped_parameters,lr=5e-5,warmup=0.1,t_total=t_total)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJdS9f_0AJyZ"
      },
      "source": [
        "## Set epoch, start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK4WyCzJLbfl"
      },
      "source": [
        "BERT_TOKENIZER = None\n",
        "import transformers\n",
        "from typing import List\n",
        "BERT_MAX_SEQ_LEN = 512\n",
        "\n",
        "def merge_subtokens(tokens: List):\n",
        "    merged_tokens = []\n",
        "    for token in tokens:\n",
        "        if token.startswith(\"##\"):\n",
        "            merged_tokens[-1] = merged_tokens[-1] + token[2:]\n",
        "        else:\n",
        "            merged_tokens.append(token)\n",
        "    text = \" \".join(merged_tokens)\n",
        "    return text\n",
        "\n",
        "def _custom_bert_tokenize_sentence(text):\n",
        "    tokens = BERT_TOKENIZER.tokenize(text)\n",
        "    tokens = tokens[:BERT_MAX_SEQ_LEN - 2]  # 2 allowed for [CLS] and [SEP]\n",
        "    idxs = np.array([idx for idx, token in enumerate(tokens) if not token.startswith(\"##\")] + [len(tokens)])\n",
        "    split_sizes = (idxs[1:] - idxs[0:-1]).tolist()\n",
        "    # NOTE: BERT tokenizer does more than just splitting at whitespace and tokenizing. So be careful.\n",
        "    # -----> assert len(split_sizes)==len(text.split()), print(len(tokens), len(split_sizes), len(text.split()), split_sizes, text)\n",
        "    # -----> hence do the following:\n",
        "    text = merge_subtokens(tokens)\n",
        "    assert len(split_sizes) == len(text.split()), print(len(tokens), len(split_sizes), len(text.split()), split_sizes,\n",
        "                                                        text)\n",
        "    return text, tokens, split_sizes\n",
        "\n",
        "def _custom_bert_tokenize_sentences(list_of_texts):\n",
        "    out = [_custom_bert_tokenize_sentence(text) for text in list_of_texts]\n",
        "    texts, tokens, split_sizes = list(zip(*out))\n",
        "    return [*texts], [*tokens], [*split_sizes]\n",
        "\n",
        "def _simple_bert_tokenize_sentences(list_of_texts):\n",
        "    return [merge_subtokens(BERT_TOKENIZER.tokenize(text)[:BERT_MAX_SEQ_LEN - 2]) for text in list_of_texts]\n",
        "\n",
        "def bert_tokenize_for_valid_examples(batch_orginal_sentences, batch_noisy_sentences, bert_pretrained_name_or_path=bert_pretrained_name_or_path):\n",
        "    \"\"\"\n",
        "    inputs:\n",
        "        batch_noisy_sentences: List[str]\n",
        "            a list of textual sentences to tokenized\n",
        "        batch_orginal_sentences: List[str]\n",
        "            a list of texts to make sure lengths of input and output are same in the seq-modeling task\n",
        "        bert_pretrained_name_or_path:\n",
        "            a huggingface path for loading a custom bert model\n",
        "    outputs (only of batch_noisy_sentences):\n",
        "        batch_attention_masks, batch_input_ids, batch_token_type_ids\n",
        "            2d tensors of shape (bs,max_len)\n",
        "        batch_splits: List[List[Int]]\n",
        "            specifies #sub-tokens for each word in each textual string after sub-word tokenization\n",
        "    \"\"\"\n",
        "    global BERT_TOKENIZER\n",
        "\n",
        "    if BERT_TOKENIZER is None:  # gets initialized during the first call to this method\n",
        "        if bert_pretrained_name_or_path:\n",
        "            BERT_TOKENIZER = transformers.BertTokenizer.from_pretrained(bert_pretrained_name_or_path)\n",
        "            BERT_TOKENIZER.do_basic_tokenize = True\n",
        "            BERT_TOKENIZER.tokenize_chinese_chars = False\n",
        "        else:\n",
        "            BERT_TOKENIZER = transformers.BertTokenizer.from_pretrained(bert_pretrained_name_or_path)\n",
        "            BERT_TOKENIZER.do_basic_tokenize = True\n",
        "            BERT_TOKENIZER.tokenize_chinese_chars = False\n",
        "\n",
        "    _batch_orginal_sentences = _simple_bert_tokenize_sentences(batch_orginal_sentences)\n",
        "    _batch_noisy_sentences, _batch_tokens, _batch_splits = _custom_bert_tokenize_sentences(batch_noisy_sentences)\n",
        "\n",
        "    valid_idxs = [idx for idx, (a, b) in enumerate(zip(_batch_orginal_sentences, _batch_noisy_sentences)) if\n",
        "                  len(a.split()) == len(b.split())]\n",
        "    batch_orginal_sentences = [line for idx, line in enumerate(_batch_orginal_sentences) if idx in valid_idxs]\n",
        "    batch_noisy_sentences = [line for idx, line in enumerate(_batch_noisy_sentences) if idx in valid_idxs]\n",
        "    batch_tokens = [line for idx, line in enumerate(_batch_tokens) if idx in valid_idxs]\n",
        "    batch_splits = [line for idx, line in enumerate(_batch_splits) if idx in valid_idxs]\n",
        "\n",
        "    batch_bert_dict = {\n",
        "        \"attention_mask\": [],\n",
        "        \"input_ids\": [],\n",
        "        # \"token_type_ids\": []\n",
        "    }\n",
        "    if len(valid_idxs) > 0:\n",
        "        batch_encoded_dicts = [BERT_TOKENIZER.encode_plus(tokens) for tokens in batch_tokens]\n",
        "        batch_attention_masks = pad_sequence(\n",
        "            [torch.tensor(encoded_dict[\"attention_mask\"]) for encoded_dict in batch_encoded_dicts], batch_first=True,\n",
        "            padding_value=0)\n",
        "        batch_input_ids = pad_sequence(\n",
        "            [torch.tensor(encoded_dict[\"input_ids\"]) for encoded_dict in batch_encoded_dicts], batch_first=True,\n",
        "            padding_value=0)\n",
        "        # batch_token_type_ids = pad_sequence(\n",
        "        #     [torch.tensor(encoded_dict[\"token_type_ids\"]) for encoded_dict in batch_encoded_dicts], batch_first=True,\n",
        "        #     padding_value=0)\n",
        "        batch_bert_dict = {\"attention_mask\": batch_attention_masks,\n",
        "                           \"input_ids\": batch_input_ids,\n",
        "                           # \"token_type_ids\": batch_token_type_ids\n",
        "                           }\n",
        "\n",
        "    return batch_orginal_sentences, batch_noisy_sentences, batch_bert_dict, batch_splits"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqh28V51yCxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6044a4-0760-48ba-8617-c4a3c769286f"
      },
      "source": [
        "# train and eval\n",
        "for epoch_id in range(START_EPOCH,N_EPOCHS+1):\n",
        "\n",
        "    print(f\"In epoch: {epoch_id}\")\n",
        "\n",
        "    # train loss and backprop\n",
        "    train_loss = 0.\n",
        "    train_acc = 0.\n",
        "    train_acc_count = 0.\n",
        "    print(\"train_data size: {}\".format(len(train_data)))\n",
        "    \n",
        "    train_data_iter = batch_iter(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "    nbatches = int(np.ceil(len(train_data)/TRAIN_BATCH_SIZE))\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for batch_id, (batch_labels,batch_sentences) in enumerate(train_data_iter):\n",
        "        optimizer.zero_grad()\n",
        "        st_time = time.time()\n",
        "\n",
        "        # set batch data for bert\n",
        "        batch_labels_, batch_sentences_, batch_bert_inp, batch_bert_splits = bert_tokenize_for_valid_examples(batch_labels,batch_sentences,bert_pretrained_name_or_path=bert_pretrained_name_or_path)                \n",
        "        if len(batch_labels_)==0:\n",
        "            print(\"################\")\n",
        "            print(\"Not training the following lines due to pre-processing mismatch: \\n\")\n",
        "            print([(a,b) for a,b in zip(batch_labels,batch_sentences)])\n",
        "            print(\"################\")\n",
        "            continue\n",
        "        else:\n",
        "            batch_labels, batch_sentences = batch_labels_, batch_sentences_\n",
        "\n",
        "        batch_bert_inp = {k:v.to(DEVICE) for k,v in batch_bert_inp.items()}\n",
        "\n",
        "        # set batch data for others\n",
        "        batch_labels, batch_lengths = labelize(batch_labels, vocab)\n",
        "        batch_lengths = batch_lengths.to(DEVICE)\n",
        "        batch_labels = batch_labels.to(DEVICE)\n",
        "\n",
        "        # forward\n",
        "        model.train()\n",
        "        \n",
        "        loss = model(batch_bert_inp, batch_bert_splits, targets=batch_labels)\n",
        "        \n",
        "        batch_loss = loss.cpu().detach().numpy()\n",
        "        train_loss += batch_loss\n",
        "\n",
        "        # backward\n",
        "        # if GRADIENT_ACC > 1:\n",
        "        #     loss = loss / GRADIENT_ACC\n",
        "        loss.backward()\n",
        "        # step\n",
        "        # if (batch_id + 1) % GRADIENT_ACC == 0 or batch_id >= nbatches - 1:\n",
        "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "            # scheduler.step()\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        # compute accuracy in numpy\n",
        "        if batch_id%10000==0:\n",
        "\n",
        "            train_acc_count += 1\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                _, batch_predictions = model(batch_bert_inp, batch_bert_splits, targets=batch_labels)\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            batch_labels = batch_labels.cpu().detach().numpy()\n",
        "            batch_lengths = batch_lengths.cpu().detach().numpy()\n",
        "            ncorr,ntotal = batch_accuracy_func(batch_predictions,batch_labels,batch_lengths)\n",
        "            batch_acc = ncorr/ntotal\n",
        "            train_acc += batch_acc     \n",
        "\n",
        "        # update progress\n",
        "        progressBar(batch_id+1,\n",
        "                    int(np.ceil(len(train_data) / TRAIN_BATCH_SIZE)), \n",
        "                    [\"batch_time\",\"batch_loss\",\"avg_batch_loss\",\"batch_acc\",\"avg_batch_acc\"],\n",
        "                    [time.time()-st_time,batch_loss,train_loss/(batch_id+1),batch_acc,train_acc/train_acc_count]) \n",
        "    \n",
        "    print(f\"\\nEpoch {epoch_id} train_loss: {train_loss/(batch_id+1)}\")\n",
        "\n",
        "    # save model every epoch\n",
        "    model_name = \"bert_epoch_\" + str(epoch_id) + '.pt'\n",
        "    # torch.save(model.state_dict(), \n",
        "    #         '/content/drive/MyDrive/NLP/'+model_name)\n",
        "\n",
        "    # valid loss\n",
        "    valid_loss = 0.\n",
        "    valid_acc = 0.\n",
        "    print(\"valid_data size: {}\".format(len(valid_data)))\n",
        "\n",
        "    valid_data_iter = batch_iter(valid_data, batch_size=VALID_BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    for batch_id, (batch_labels,batch_sentences) in enumerate(valid_data_iter):\n",
        "\n",
        "        st_time = time.time()\n",
        "        # set batch data for bert\n",
        "        # batch_labels_, batch_sentences_, batch_bert_inp, batch_bert_splits = bert_tokenize_for_valid_examples(batch_labels,batch_sentences)\n",
        "\n",
        "        batch_labels, batch_sentences, batch_bert_inp, batch_bert_splits = bert_tokenize_for_valid_examples(batch_labels,batch_sentences)\n",
        "        \"\"\"\n",
        "        if len(batch_labels_)==0:\n",
        "            print(\"################\")\n",
        "            print(\"Not validating the following lines due to pre-processing mismatch: \\n\")\n",
        "            print([(a,b) for a,b in zip(batch_labels,batch_sentences)])\n",
        "            print(\"################\")\n",
        "            continue\n",
        "        else:\n",
        "        \n",
        "            batch_labels, batch_sentences = batch_labels_, batch_sentences_\n",
        "        \"\"\"\n",
        "\n",
        "        batch_bert_inp = {k:v.to(DEVICE) for k,v in batch_bert_inp.items()}\n",
        "\n",
        "\n",
        "        # set batch data for others\n",
        "        batch_labels, batch_lengths = labelize(batch_labels, vocab)\n",
        "        batch_lengths = batch_lengths.to(DEVICE)\n",
        "        batch_labels = batch_labels.to(DEVICE)\n",
        "\n",
        "        # forward\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            batch_loss, batch_predictions = model(batch_bert_inp, batch_bert_splits, targets=batch_labels)\n",
        "        model.train()        \n",
        "        valid_loss += batch_loss\n",
        "        # compute accuracy in numpy\n",
        "        batch_labels = batch_labels.cpu().detach().numpy()\n",
        "        batch_lengths = batch_lengths.cpu().detach().numpy()\n",
        "        ncorr,ntotal = batch_accuracy_func(batch_predictions,batch_labels,batch_lengths)\n",
        "        batch_acc = ncorr/ntotal\n",
        "        valid_acc += batch_acc\n",
        "        # update progress\n",
        "        progressBar(batch_id+1,\n",
        "                    int(np.ceil(len(valid_data) / VALID_BATCH_SIZE)), \n",
        "                    [\"batch_time\",\"batch_loss\",\"avg_batch_loss\",\"batch_acc\",\"avg_batch_acc\"], \n",
        "                    [time.time()-st_time,batch_loss,valid_loss/(batch_id+1),batch_acc,valid_acc/(batch_id+1)])\n",
        "\n",
        "    print(f\"\\nEpoch {epoch_id} valid_loss: {valid_loss/(batch_id+1)}\")\n",
        "    torch.save({\n",
        "            'epoch': epoch_id,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': valid_loss}, f'/content/gdrive/MyDrive/mdistilepoch:{epoch_id}valid_acc{valid_acc/(batch_id+1)}.hdf5')\n",
        "\n",
        "  "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In epoch: 1\n",
            "train_data size: 245821\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.1718 || batch_loss: 0.7838 || avg_batch_loss: 1.2178 || batch_acc: 0.0589 || avg_batch_acc: 0.0589 \n",
            "Epoch 1 train_loss: 1.2178346347728144\n",
            "valid_data size: 27313\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.0527 || batch_loss: 0.3786 || avg_batch_loss: 0.3914 || batch_acc: 0.9408 || avg_batch_acc: 0.9391 \n",
            "Epoch 1 valid_loss: 0.3914380107048803\n",
            "In epoch: 2\n",
            "train_data size: 245821\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.1968 || batch_loss: 0.2421 || avg_batch_loss: 0.2991 || batch_acc: 0.9507 || avg_batch_acc: 0.9507 \n",
            "Epoch 2 train_loss: 0.29905201979825285\n",
            "valid_data size: 27313\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.0516 || batch_loss: 0.2482 || avg_batch_loss: 0.2164 || batch_acc: 0.9590 || avg_batch_acc: 0.9585 \n",
            "Epoch 2 valid_loss: 0.21636014773708875\n",
            "In epoch: 3\n",
            "train_data size: 245821\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.1882 || batch_loss: 0.1910 || avg_batch_loss: 0.1536 || batch_acc: 0.9820 || avg_batch_acc: 0.9820 \n",
            "Epoch 3 train_loss: 0.15358002591549388\n",
            "valid_data size: 27313\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.0522 || batch_loss: 0.2104 || avg_batch_loss: 0.1717 || batch_acc: 0.9590 || avg_batch_acc: 0.9649 \n",
            "Epoch 3 valid_loss: 0.1717462252991261\n",
            "In epoch: 4\n",
            "train_data size: 245821\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.1774 || batch_loss: 0.0984 || avg_batch_loss: 0.0909 || batch_acc: 0.9935 || avg_batch_acc: 0.9935 \n",
            "Epoch 4 train_loss: 0.09086161970547155\n",
            "valid_data size: 27313\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.0529 || batch_loss: 0.2393 || avg_batch_loss: 0.1656 || batch_acc: 0.9636 || avg_batch_acc: 0.9663 \n",
            "Epoch 4 valid_loss: 0.16562780779317476\n",
            "In epoch: 5\n",
            "train_data size: 245821\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.1736 || batch_loss: 0.0625 || avg_batch_loss: 0.0608 || batch_acc: 0.9974 || avg_batch_acc: 0.9974 \n",
            "Epoch 5 train_loss: 0.06079279382397202\n",
            "valid_data size: 27313\n",
            "Percent: [----------------------------->] 100% || batch_time: 0.0521 || batch_loss: 0.1945 || avg_batch_loss: 0.1653 || batch_acc: 0.9704 || avg_batch_acc: 0.9672 \n",
            "Epoch 5 valid_loss: 0.16528566543719528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUbevWLeAUvb"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-zb8Iug02Ba"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from neuspell.seq_modeling.evals import get_metrics\n",
        "\n",
        "def untokenize_without_unks(batch_predictions, batch_lengths, vocab, batch_clean_sentences, backoff=\"pass-through\"):\n",
        "    assert backoff in [\"neutral\", \"pass-through\"], print(f\"selected backoff strategy not implemented: {backoff}\")\n",
        "    idx2token = vocab[\"idx2token\"]\n",
        "    unktoken = vocab[\"token2idx\"][vocab[\"unk_token\"]]\n",
        "    assert len(batch_predictions) == len(batch_lengths) == len(batch_clean_sentences)\n",
        "    batch_clean_sentences = [sent.split() for sent in batch_clean_sentences]\n",
        "    if backoff == \"pass-through\":\n",
        "        batch_predictions = \\\n",
        "            [\" \".join([idx2token[idx] if idx != unktoken else clean_[i] for i, idx in enumerate(pred_[:len_])]) \\\n",
        "             for pred_, len_, clean_ in zip(batch_predictions, batch_lengths, batch_clean_sentences)]\n",
        "    elif backoff == \"neutral\":\n",
        "        batch_predictions = \\\n",
        "            [\" \".join([idx2token[idx] if idx != unktoken else \"a\" for i, idx in enumerate(pred_[:len_])]) \\\n",
        "             for pred_, len_, clean_ in zip(batch_predictions, batch_lengths, batch_clean_sentences)]\n",
        "    return batch_predictions\n",
        "\n",
        "def batch_iter(data, batch_size, shuffle):\n",
        "    \"\"\"\n",
        "    each data item is a tuple of lables and text\n",
        "    \"\"\"\n",
        "    n_batches = int(np.ceil(len(data) / batch_size))\n",
        "    indices = list(range(len(data)))\n",
        "    if shuffle:  np.random.shuffle(indices)\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        batch_indices = indices[i * batch_size: (i + 1) * batch_size]\n",
        "        batch_labels = [data[idx][0] for idx in batch_indices]\n",
        "        batch_sentences = [data[idx][1] for idx in batch_indices]\n",
        "\n",
        "        yield (batch_labels, batch_sentences)\n",
        "\n",
        "def model_inference(model, data, topk, device, batch_size=16, vocab_=None):\n",
        "    \"\"\"\n",
        "    model: an instance of SubwordBert\n",
        "    data: list of tuples, with each tuple consisting of correct and incorrect \n",
        "            sentence string (would be split at whitespaces)\n",
        "    topk: how many of the topk softmax predictions are considered for metrics calculations\n",
        "    \"\"\"\n",
        "    if vocab_ is not None:\n",
        "        vocab = vocab_\n",
        "    print(\"###############################################\")\n",
        "    inference_st_time = time.time()\n",
        "    _corr2corr, _corr2incorr, _incorr2corr, _incorr2incorr = 0, 0, 0, 0\n",
        "    _mistakes = []\n",
        "    VALID_batch_size = batch_size\n",
        "    valid_loss = 0.\n",
        "    valid_acc = 0.\n",
        "    print(\"data size: {}\".format(len(data)))\n",
        "    data_iter = batch_iter(data, batch_size=VALID_batch_size, shuffle=False)\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    for batch_id, (batch_labels, batch_sentences) in tqdm(enumerate(data_iter)):\n",
        "        torch.cuda.empty_cache()\n",
        "        st_time = time.time()\n",
        "        # set batch data for bert\n",
        "        batch_labels_, batch_sentences_, batch_bert_inp, batch_bert_splits = bert_tokenize_for_valid_examples(\n",
        "            batch_labels, batch_sentences, bert_pretrained_name_or_path=bert_pretrained_name_or_path)\n",
        "        if len(batch_labels_) == 0:\n",
        "            print(\"################\")\n",
        "            print(\"Not predicting the following lines due to pre-processing mismatch: \\n\")\n",
        "            print([(a, b) for a, b in zip(batch_labels, batch_sentences)])\n",
        "            print(\"################\")\n",
        "            continue\n",
        "        else:\n",
        "            batch_labels, batch_sentences = batch_labels_, batch_sentences_\n",
        "        batch_bert_inp = {k: v.to(device) for k, v in batch_bert_inp.items()}\n",
        "        # set batch data for others\n",
        "        batch_labels_ids, batch_lengths = labelize(batch_labels, vocab)\n",
        "        # batch_lengths = batch_lengths.to(device)\n",
        "        batch_labels_ids = batch_labels_ids.to(device)\n",
        "        # forward\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                \"\"\"\n",
        "                NEW: batch_predictions can now be of shape (batch_size,batch_max_seq_len,topk) if topk>1, else (batch_size,batch_max_seq_len)\n",
        "                \"\"\"\n",
        "                batch_loss, batch_predictions = model(batch_bert_inp, batch_bert_splits, targets=batch_labels_ids,\n",
        "                                                      topk=topk)\n",
        "                print(batch_predictions)\n",
        "        except RuntimeError:\n",
        "            print(f\"batch_bert_inp:{len(batch_bert_inp.keys())},batch_labels_ids:{batch_labels_ids.shape}\")\n",
        "            raise Exception(\"\")\n",
        "        valid_loss += batch_loss\n",
        "        # compute accuracy in numpy\n",
        "        batch_labels_ids = batch_labels_ids.cpu().detach().numpy()\n",
        "        batch_lengths = batch_lengths.cpu().detach().numpy()\n",
        "        # based on topk, obtain either strings of batch_predictions or list of tokens\n",
        "        if topk == 1:\n",
        "            batch_predictions = untokenize_without_unks(batch_predictions, batch_lengths, vocab, batch_sentences)\n",
        "        else:\n",
        "            batch_predictions = untokenize_without_unks2(batch_predictions, batch_lengths, vocab, batch_sentences,\n",
        "                                                         topk=None)\n",
        "        # corr2corr, corr2incorr, incorr2corr, incorr2incorr, mistakes = \\\n",
        "        #    get_metrics(batch_labels,batch_sentences,batch_predictions,check_until_topk=topk,return_mistakes=True)\n",
        "        # _mistakes.extend(mistakes)\n",
        "        # batch_labels = [line.lower() for line in batch_labels]\n",
        "        # batch_sentences = [line.lower() for line in batch_sentences]\n",
        "        # batch_predictions = [line.lower() for line in batch_predictions]\n",
        "        print(batch_predictions)\n",
        "        corr2corr, corr2incorr, incorr2corr, incorr2incorr = \\\n",
        "            get_metrics(batch_labels, batch_sentences, batch_predictions, check_until_topk=topk, return_mistakes=False)\n",
        "        _corr2corr += corr2corr\n",
        "        _corr2incorr += corr2incorr\n",
        "        _incorr2corr += incorr2corr\n",
        "        _incorr2incorr += incorr2incorr\n",
        "\n",
        "        # delete\n",
        "        del batch_loss\n",
        "        del batch_predictions\n",
        "        del batch_labels, batch_lengths, batch_bert_inp\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        '''\n",
        "        # update progress\n",
        "        progressBar(batch_id+1,\n",
        "                    int(np.ceil(len(data) / VALID_batch_size)), \n",
        "                    [\"batch_time\",\"batch_loss\",\"avg_batch_loss\",\"batch_acc\",\"avg_batch_acc\"], \n",
        "                    [time.time()-st_time,batch_loss,valid_loss/(batch_id+1),None,None])\n",
        "        '''\n",
        "    print(f\"\\nEpoch {None} valid_loss: {valid_loss / (batch_id + 1)}\")\n",
        "    print(\"total inference time for this data is: {:4f} secs\".format(time.time() - inference_st_time))\n",
        "    print(\"###############################################\")\n",
        "    print(\"\")\n",
        "    # for mistake in _mistakes:\n",
        "    #    print(mistake)\n",
        "    print(\"\")\n",
        "    print(\"total token count: {}\".format(_corr2corr + _corr2incorr + _incorr2corr + _incorr2incorr))\n",
        "    print(\n",
        "        f\"_corr2corr:{_corr2corr}, _corr2incorr:{_corr2incorr}, _incorr2corr:{_incorr2corr}, _incorr2incorr:{_incorr2incorr}\")\n",
        "    print(f\"accuracy is {(_corr2corr + _incorr2corr) / (_corr2corr + _corr2incorr + _incorr2corr + _incorr2incorr)}\")\n",
        "    print(f\"word correction rate is {(_incorr2corr) / (_incorr2corr + _incorr2incorr)}\")\n",
        "    print(\"###############################################\")\n",
        "    return"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCtk0JhWyGW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1646e2-3c8e-4a64-b681-da1cdd1d6750"
      },
      "source": [
        "# from neuspell.seq_modeling.subwordbert import model_inference\n",
        "\n",
        "test_data = load_data('/content/neuspell/data/traintest/','test.bea60k','test.bea60k.noise')\n",
        "\n",
        "predicted_result = model_inference(model, test_data, 1, 'cuda', 16, vocab)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63044it [00:00, 401510.07it/s]\n",
            "63044it [00:00, 1328645.51it/s]\n",
            "1it [00:00,  5.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loaded tuples of (corr,incorr) examples from /content/neuspell/data/traintest/\n",
            "###############################################\n",
            "data size: 63044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3941it [03:07, 20.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch None valid_loss: 0.23158685709979593\n",
            "total inference time for this data is: 187.966454 secs\n",
            "###############################################\n",
            "\n",
            "\n",
            "total token count: 1059069\n",
            "_corr2corr:969517, _corr2incorr:19542, _incorr2corr:48129, _incorr2incorr:21881\n",
            "accuracy is 0.9608873453948704\n",
            "word correction rate is 0.6874589344379375\n",
            "###############################################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc33y9sNNUQk",
        "outputId": "bfa56243-1804-47f3-9fe6-7f4e7ffb115a"
      },
      "source": [
        "\n",
        "test_data = load_data('/content/neuspell/data/traintest/','test.jfleg','test.jfleg.noise')\n",
        "\n",
        "predicted_result = model_inference(model, test_data, 1, 'cuda', 16, vocab)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1601it [00:00, 268990.57it/s]\n",
            "1601it [00:00, 999416.68it/s]\n",
            "2it [00:00, 19.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loaded tuples of (corr,incorr) examples from /content/neuspell/data/traintest/\n",
            "###############################################\n",
            "data size: 1601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "101it [00:05, 17.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch None valid_loss: 0.15700027958425408\n",
            "total inference time for this data is: 5.727958 secs\n",
            "###############################################\n",
            "\n",
            "\n",
            "total token count: 33473\n",
            "_corr2corr:31132, _corr2incorr:331, _incorr2corr:1505, _incorr2incorr:505\n",
            "accuracy is 0.9750246467302005\n",
            "word correction rate is 0.7487562189054726\n",
            "###############################################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}